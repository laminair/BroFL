{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports\n",
    "import utils\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from adjustText import adjust_text\n",
    "\n",
    "notebook_path = os.path.dirname(os.path.realpath(\"01_client_dropout_analysis.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn configuration\n",
    "# Alternative font: Linux Libertine\n",
    "sns.set_theme(context=\"paper\", style=\"whitegrid\", palette=\"colorblind\", font=\"Times New Roman\", font_scale=3)\n",
    "sns.color_palette(palette=\"colorblind\")\n",
    "sns.set(rc={\"figure.figsize\": (14, 4)})\n",
    "sns.set(font_scale=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download / load from disk\n",
    "wandb_entity = \"...\"                                                                                                            # <-- Add you credentials for W&B here.\n",
    "wandb_project = \"...\"                                                                                                           # <-- Add you credentials for W&B here.\n",
    "wandb_run_filter_keywords = [\"...\"]                                                                                             # <-- Add you credentials for W&B here.\n",
    "log_file_name = \"wandb_dropout_dp_logs.csv\"\n",
    "\n",
    "if not Path(f\"{notebook_path}/data/{log_file_name}\").exists():\n",
    "    # If logs have been downloaded already, they will be fetched from disk.\n",
    "    df = utils.download_data_from_wandb(entity=wandb_entity, project=wandb_project, keywords=wandb_run_filter_keywords)\n",
    "    df = utils.expand_experiment_name(df)\n",
    "    utils.write_df_to_disk(df, filename=log_file_name)\n",
    "else:\n",
    "    df = pd.read_csv(f\"{notebook_path}/data/{log_file_name}\", index_col=0)\n",
    "    df = utils.expand_experiment_name(df)\n",
    "    utils.write_df_to_disk(df, filename=log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prox_mnist = df.loc[(df[\"dataset\"] == \"mnist\") & (df[\"strategy\"] == \"fedprox\") & (df[\"data_dist\"] == \"dirichlet\") & (df[\"dp\"] == \"False\")]\n",
    "prox_pvt = prox_mnist.pivot_table(index=[\"dropout\", \"strategy\"], columns=[\"dataset\", \"model\"], values=[\"global_performance/accuracy\"], aggfunc=[np.mean])\n",
    "print(prox_pvt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RQ 3: Client Dropout analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.loc[df[\"dp\"] == \"False\"] # We are not interested in DP experiments at this stage.\n",
    "df3 = df3.loc[(df3[\"global_performance/f1_score\"].notna()) & (df3[\"global_performance/f1_score\"].notna())]\n",
    "print(df[\"dp\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We report the global accuracy after the first, fifth, and last training round\n",
    "df3 = df3[[\"dataset\", \"model\", \"strategy\", \"data_dist\", \"dropout\", \"epoch\", \"dp\", \"global_performance/accuracy\", \"global_performance/f1_score\", \"timing/evaluation_time\", \"_step\", \"id\"]]\n",
    "\n",
    "table_df3 = pd.DataFrame()\n",
    "for dataset in [\"blond\", \"mnist\", \"shakespeare\"]:\n",
    "    for model in [\"cnn\", \"lstm\", \"resnet\", \"densenet\"]:\n",
    "        for strategy in [\"fedavg\", \"qfedavg\", \"fedadam\", \"fedyogi\", \"fedadagrad\", \"fedprox\"]:\n",
    "            for dropout in [0, 1, 2, 5]:\n",
    "                subset = df3.loc[(df3[\"dataset\"] == dataset) & (df3[\"model\"] == model) & (df3[\"strategy\"] == strategy) & (df3[\"dropout\"] == str(dropout)) & (df3[\"data_dist\"] == \"dirichlet\") & (df3[\"dp\"] == \"False\")]\n",
    "                if len(subset) == 0:\n",
    "                    continue\n",
    "\n",
    "                experiments = subset[\"id\"].unique().tolist()\n",
    "\n",
    "                data = {\"dataset\": dataset, \"model\": model, \"strategy\": strategy, \"dropout\": dropout, \"data_dist\": \"dirichlet\"}\n",
    "                exp_data = {\"f1\": [], \"acc\": []}\n",
    "                for experiment in experiments:\n",
    "                    exp = subset.loc[subset[\"id\"] == experiment]\n",
    "                    f1 = exp[\"global_performance/f1_score\"].unique().tolist()\n",
    "                    acc = exp[\"global_performance/accuracy\"].unique().tolist()\n",
    "\n",
    "                    while len(f1) != 11:\n",
    "                        f1.append(f1[-1])\n",
    "\n",
    "                    while len(acc) != 11:\n",
    "                        acc.append(acc[-1])\n",
    "\n",
    "                    exp_data[\"f1\"].append(f1)\n",
    "                    exp_data[\"acc\"].append(acc)\n",
    "\n",
    "                for rnd in range(0, 11):\n",
    "                    round_vals = []\n",
    "                    for exp in exp_data[\"f1\"]:\n",
    "                        round_vals.append(exp[rnd])\n",
    "\n",
    "                    data[f\"f1_round_{rnd}\"] = np.nanmean(round_vals)\n",
    "                    data[f\"f1_round_{rnd}_stddev\"] = np.nanstd(round_vals)\n",
    "\n",
    "                    round_vals = []\n",
    "                    for exp in exp_data[\"acc\"]:\n",
    "                        round_vals.append(exp[rnd])\n",
    "\n",
    "                    data[f\"acc_round_{rnd}\"] = np.mean(round_vals)\n",
    "                    data[f\"acc_round_{rnd}_stddev\"] = np.std(round_vals)\n",
    "\n",
    "                table_df3 = pd.concat([table_df3, pd.DataFrame(data, index=[0])])\n",
    "#\n",
    "table_df3 = table_df3.round(decimals=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we investigate all non-IID datasets with Dirichlet alpha = 1.\n",
    "table_df3[\"dropout\"].replace([0, 1, 2, 5], [0, 0.1, 0.2, 0.5], inplace=True)\n",
    "table_df3[\"strategy\"].replace([\"fedavg\", \"fedadam\", \"fedadagrad\", \"fedyogi\", \"qfedavg\", \"fedprox\"], [\"FedAvg\", \"FedAdam\", \"FedAdaGrad\", \"FedYogi\", \"qFedAvg\", \"FedProx\"], inplace=True)\n",
    "table_df3[\"dataset\"].replace([\"blond\", \"mnist\", \"shakespeare\"], [\"BLOND\", \"FEMNIST\", \"Shakespeare\"], inplace=True)\n",
    "table_df3[\"model\"].replace([\"cnn\", \"lstm\", \"resnet\", \"densenet\"], [\"CNN\", \"LSTM\", \"ResNet\", \"DenseNet\"], inplace=True)\n",
    "\n",
    "piv3 = table_df3.pivot_table(index=[\"dropout\", \"strategy\"], columns=[\"dataset\", \"model\"], values=[\"acc_round_10\", \"acc_round_10_stddev\"])\n",
    "\n",
    "for acc, dataset, model in [i for i in piv3.columns]:\n",
    "    if \"_stddev\" not in acc:\n",
    "        piv3[(acc, dataset, model)] = piv3[(acc, dataset, model)].round(decimals=2).astype(str)+ \"±\" + piv3[(f\"{acc}_stddev\", dataset, model)].round(decimals=2).astype(str)\n",
    "    else:\n",
    "        piv3.drop((acc, dataset, model), inplace=True, axis=1)\n",
    "\n",
    "s = piv3.style.highlight_max(props='cellcolor:[HTML]{FFFF00}; color:{red}; itshape:; bfseries:;')\n",
    "s.clear()\n",
    "s.table_styles = []\n",
    "s.format({\n",
    "\t(\"Numeric\", \"Integers\"): '\\${}',\n",
    "\t(\"Numeric\", \"Floats\"): '{:.2f}',\n",
    "    (\"Non-Numeric\", \"Strings\"): str.upper\n",
    "})\n",
    "print(s.to_latex(column_format=\"ll|rrrr|r|r\", position=\"\", position_float=\"centering\", hrules=True, label=\"tab:speedup-comparison\", caption=\"Speedup comparison across device types, datasets, and ML models.\", multirow_align=\"t\", multicol_align=\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We report the global accuracy after the first, fifth, and last training round\n",
    "df4 = df3[[\"dataset\", \"model\", \"strategy\", \"data_dist\", \"dropout\", \"epoch\", \"dp\", \"global_performance/accuracy\", \"global_performance/f1_score\", \"timing/evaluation_time\", \"_step\", \"id\"]]\n",
    "\n",
    "table_df4 = pd.DataFrame()\n",
    "for dataset in [\"blond\", \"mnist\", \"shakespeare\"]:\n",
    "    for model in [\"cnn\", \"lstm\", \"resnet\", \"densenet\"]:\n",
    "        for strategy in [\"fedavg\", \"qfedavg\", \"fedadam\", \"fedyogi\", \"fedadagrad\", \"fedprox\"]:\n",
    "            for dropout in [0, 1, 2, 5]:\n",
    "                subset = df4.loc[(df4[\"dataset\"] == dataset) & (df4[\"model\"] == model) & (df4[\"strategy\"] == strategy) & (df4[\"dropout\"] == str(dropout)) & (df4[\"data_dist\"] == \"iid\") & (df4[\"dp\"] == \"False\")]\n",
    "                if len(subset) == 0:\n",
    "                    continue\n",
    "\n",
    "                experiments = subset[\"id\"].unique().tolist()\n",
    "\n",
    "                data = {\"dataset\": dataset, \"model\": model, \"strategy\": strategy, \"dropout\": dropout, \"data_dist\": \"dirichlet\"}\n",
    "                exp_data = {\"f1\": [], \"acc\": []}\n",
    "                for experiment in experiments:\n",
    "                    exp = subset.loc[subset[\"id\"] == experiment]\n",
    "                    f1 = exp[\"global_performance/f1_score\"].unique().tolist()\n",
    "                    acc = exp[\"global_performance/accuracy\"].unique().tolist()\n",
    "\n",
    "                    while len(f1) != 11:\n",
    "                        f1.append(f1[-1])\n",
    "\n",
    "                    while len(acc) != 11:\n",
    "                        acc.append(acc[-1])\n",
    "\n",
    "                    exp_data[\"f1\"].append(f1)\n",
    "                    exp_data[\"acc\"].append(acc)\n",
    "\n",
    "                for rnd in range(0, 11):\n",
    "                    round_vals = []\n",
    "                    for exp in exp_data[\"f1\"]:\n",
    "                        round_vals.append(exp[rnd])\n",
    "\n",
    "                    data[f\"f1_round_{rnd}\"] = np.nanmean(round_vals)\n",
    "                    data[f\"f1_round_{rnd}_stddev\"] = np.nanstd(round_vals)\n",
    "\n",
    "                    round_vals = []\n",
    "                    for exp in exp_data[\"acc\"]:\n",
    "                        round_vals.append(exp[rnd])\n",
    "\n",
    "                    data[f\"acc_round_{rnd}\"] = np.mean(round_vals)\n",
    "                    data[f\"acc_round_{rnd}_stddev\"] = np.std(round_vals)\n",
    "\n",
    "                table_df4 = pd.concat([table_df4, pd.DataFrame(data, index=[0])])\n",
    "#\n",
    "table_df4 = table_df4.round(decimals=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we investigate all non-IID datasets with Dirichlet alpha = 1.\n",
    "table_df4[\"dropout\"].replace([0, 1, 2, 5], [0, 0.1, 0.2, 0.5], inplace=True)\n",
    "table_df4[\"strategy\"].replace([\"fedavg\", \"fedadam\", \"fedadagrad\", \"fedyogi\", \"qfedavg\", \"fedprox\"], [\"FedAvg\", \"FedAdam\", \"FedAdaGrad\", \"FedYogi\", \"qFedAvg\", \"FedProx\"], inplace=True)\n",
    "table_df4[\"dataset\"].replace([\"blond\", \"mnist\", \"shakespeare\"], [\"BLOND\", \"FEMNIST\", \"Shakespeare\"], inplace=True)\n",
    "table_df4[\"model\"].replace([\"cnn\", \"lstm\", \"resnet\", \"densenet\"], [\"CNN\", \"LSTM\", \"ResNet\", \"DenseNet\"], inplace=True)\n",
    "\n",
    "piv4 = table_df4.pivot_table(index=[\"dropout\", \"strategy\"], columns=[\"dataset\", \"model\"], values=[\"acc_round_10\", \"acc_round_10_stddev\"])\n",
    "\n",
    "for acc, dataset, model in [i for i in piv3.columns]:\n",
    "    if \"_stddev\" not in acc:\n",
    "        piv4[(acc, dataset, model)] = piv4[(acc, dataset, model)].round(decimals=2).astype(str)+ \"±\" + piv4[(f\"{acc}_stddev\", dataset, model)].round(decimals=2).astype(str)\n",
    "    else:\n",
    "        piv3.drop((acc, dataset, model), inplace=True, axis=1)\n",
    "\n",
    "s = piv4.style.highlight_max(props='cellcolor:[HTML]{FFFF00}; color:{red}; itshape:; bfseries:;')\n",
    "s.clear()\n",
    "s.table_styles = []\n",
    "s.format({\n",
    "\t(\"Numeric\", \"Integers\"): '\\${}',\n",
    "\t(\"Numeric\", \"Floats\"): '{:.2f}',\n",
    "    (\"Non-Numeric\", \"Strings\"): str.upper\n",
    "})\n",
    "print(s.to_latex(column_format=\"ll|rrrr|r|r\", position=\"\", position_float=\"centering\", hrules=True, label=\"tab:speedup-comparison\", caption=\"Speedup comparison across device types, datasets, and ML models.\", multirow_align=\"t\", multicol_align=\"r\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RQ 4: Differential Privacy Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.loc[df[\"dp\"] == \"True\"] # We are not interested in DP experiments at this stage.\n",
    "df4_acc = df4.loc[(df4[\"global_performance/f1_score\"].notna()) & (df4[\"global_performance/f1_score\"].notna())]\n",
    "df4_eps = df4.loc[df4[\"dp/epsilon\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We report the global accuracy after the first, fifth, and last training round\n",
    "df4_acc = df4_acc[[\"dataset\", \"model\", \"strategy\", \"data_dist\", \"dropout\", \"epoch\", \"global_performance/accuracy\", \"global_performance/f1_score\", \"id\", \"noise_multiplier\"]].copy()\n",
    "df4_eps = df4_eps[[\"dataset\", \"model\", \"strategy\", \"data_dist\", \"dropout\", \"id\", \"dp\", \"noise_multiplier\", \"dp/epsilon\"]].copy()\n",
    "# print(df4_eps)\n",
    "\n",
    "table_df4 = pd.DataFrame()\n",
    "for dataset in [\"blond\", \"mnist\", \"shakespeare\"]:\n",
    "    for model in [\"cnn\", \"lstm\", \"resnet\", \"densenet\"]:\n",
    "        for strategy in [\"fedavg\", \"qfedavg\", \"fedadam\", \"fedyogi\", \"fedadagrad\", \"fedprox\"]:\n",
    "            for noise in [0, 0.3, 0.5, 1, 1.3, 1.5]:\n",
    "                subset_acc = df4_acc.loc[(df4_acc[\"dataset\"] == dataset) & (df4_acc[\"model\"] == model) & (df4_acc[\"strategy\"] == strategy) & (df4_acc[\"dropout\"] == \"0\") & (df4_acc[\"noise_multiplier\"] == str(noise))]\n",
    "                subset_eps = df4_eps.loc[(df4_eps[\"dataset\"] == dataset) & (df4_eps[\"model\"] == model) & (df4_eps[\"strategy\"] == strategy) & (df4_eps[\"noise_multiplier\"] == str(noise))]\n",
    "\n",
    "                if len(subset_acc) == 0:\n",
    "                    continue\n",
    "\n",
    "                experiments = subset_acc[\"id\"].unique().tolist()\n",
    "                data = {\"dataset\": dataset, \"model\": model, \"strategy\": strategy, \"noise_multiplier\": noise}\n",
    "                exp_data = {\"f1\": [], \"acc\": [], \"eps\": []}\n",
    "                for experiment in experiments:\n",
    "                    exp_acc = subset_acc.loc[subset_acc[\"id\"] == experiment]\n",
    "                    exp_eps = subset_eps.loc[subset_eps[\"id\"] == experiment]\n",
    "                    f1 = exp_acc[\"global_performance/f1_score\"].unique().tolist()\n",
    "                    acc = exp_acc[\"global_performance/accuracy\"].unique().tolist()\n",
    "                    eps = exp_eps[\"dp/epsilon\"].unique().tolist()\n",
    "\n",
    "                    while len(f1) != 11:\n",
    "                        f1.append(f1[-1])\n",
    "\n",
    "                    while len(acc) != 11:\n",
    "                        acc.append(acc[-1])\n",
    "\n",
    "                    while len(eps) != 11:\n",
    "                        eps.append(eps[-1])\n",
    "\n",
    "                    exp_data[\"f1\"].append(f1)\n",
    "                    exp_data[\"acc\"].append(acc)\n",
    "                    exp_data[\"eps\"].append(eps)\n",
    "\n",
    "                for rnd in range(0, 11):\n",
    "                    round_vals_f1 = []\n",
    "                    for exp in exp_data[\"f1\"]:\n",
    "                        round_vals_f1.append(exp[rnd])\n",
    "\n",
    "                    round_vals_acc = []\n",
    "                    for exp in exp_data[\"acc\"]:\n",
    "                        round_vals_acc.append(exp[rnd])\n",
    "\n",
    "                    round_vals_eps = []\n",
    "                    for exp in exp_data[\"eps\"]:\n",
    "                        round_vals_eps.append(exp[rnd])\n",
    "\n",
    "                    data[\"round\"] = rnd\n",
    "                    data[\"acc\"] = np.mean(round_vals_acc)\n",
    "                    data[\"acc_stddev\"] = np.std(round_vals_acc)\n",
    "                    data[\"f1\"] = np.mean(round_vals_f1)\n",
    "                    data[\"f1_stddev\"] = np.std(round_vals_f1)\n",
    "                    data[\"eps\"] = np.mean(round_vals_eps)\n",
    "                    data[\"eps_stddev\"] = np.std(round_vals_eps)\n",
    "                    table_df4 = pd.concat([table_df4, pd.DataFrame(data, index=[0])])\n",
    "\n",
    "\n",
    "table_df4 = table_df4.round(decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We report the global accuracy after the first, fifth, and last training round\n",
    "df4_acc = df4_acc[[\"dataset\", \"model\", \"strategy\", \"data_dist\", \"dropout\", \"epoch\", \"global_performance/accuracy\", \"global_performance/f1_score\", \"id\", \"noise_multiplier\"]].copy()\n",
    "df4_eps = df4_eps[[\"dataset\", \"model\", \"strategy\", \"data_dist\", \"dropout\", \"id\", \"dp\", \"noise_multiplier\", \"dp/epsilon\"]].copy()\n",
    "# print(df4_eps)\n",
    "\n",
    "table_df4 = pd.DataFrame()\n",
    "for dataset in [\"blond\", \"mnist\", \"shakespeare\"]:\n",
    "    for model in [\"0cnn\", \"1lstm\", \"2resnet\", \"3densenet\"]:\n",
    "        for strategy in [\"fedavg\", \"qfedavg\", \"fedadam\", \"fedyogi\", \"fedadagrad\", \"fedprox\"]:\n",
    "            for noise in [0, 0.3, 0.5, 1, 1.3, 1.5]:\n",
    "                subset_acc = df4_acc.loc[(df4_acc[\"dataset\"] == dataset) & (df4_acc[\"model\"] == model) & (df4_acc[\"strategy\"] == strategy) & (df4_acc[\"dropout\"] == \"0\") & (df4_acc[\"noise_multiplier\"] == str(noise))]\n",
    "                subset_eps = df4_eps.loc[(df4_eps[\"dataset\"] == dataset) & (df4_eps[\"model\"] == model) & (df4_eps[\"strategy\"] == strategy) & (df4_eps[\"noise_multiplier\"] == str(noise))]\n",
    "\n",
    "                if len(subset_acc) == 0:\n",
    "                    continue\n",
    "\n",
    "                experiments = subset_acc[\"id\"].unique().tolist()\n",
    "                data = {\"dataset\": dataset, \"model\": model, \"strategy\": strategy, \"noise_multiplier\": noise}\n",
    "                exp_data = {\"f1\": [], \"acc\": [], \"eps\": []}\n",
    "                for experiment in experiments:\n",
    "                    exp_acc = subset_acc.loc[subset_acc[\"id\"] == experiment]\n",
    "                    exp_eps = subset_eps.loc[subset_eps[\"id\"] == experiment]\n",
    "                    f1 = exp_acc[\"global_performance/f1_score\"].unique().tolist()\n",
    "                    acc = exp_acc[\"global_performance/accuracy\"].unique().tolist()\n",
    "                    eps = exp_eps[\"dp/epsilon\"].unique().tolist()\n",
    "\n",
    "                    while len(f1) != 11:\n",
    "                        f1.append(f1[-1])\n",
    "\n",
    "                    while len(acc) != 11:\n",
    "                        acc.append(acc[-1])\n",
    "\n",
    "                    while len(eps) != 11:\n",
    "                        eps.append(eps[-1])\n",
    "\n",
    "                    exp_data[\"f1\"].append(f1)\n",
    "                    exp_data[\"acc\"].append(acc)\n",
    "                    exp_data[\"eps\"].append(eps)\n",
    "\n",
    "                for rnd in range(0, 11):\n",
    "                    round_vals_f1 = []\n",
    "                    for exp in exp_data[\"f1\"]:\n",
    "                        round_vals_f1.append(exp[rnd])\n",
    "\n",
    "                    round_vals_acc = []\n",
    "                    for exp in exp_data[\"acc\"]:\n",
    "                        round_vals_acc.append(exp[rnd])\n",
    "\n",
    "                    round_vals_eps = []\n",
    "                    for exp in exp_data[\"eps\"]:\n",
    "                        round_vals_eps.append(exp[rnd])\n",
    "\n",
    "                    data[\"round\"] = rnd\n",
    "                    data[\"acc\"] = np.mean(round_vals_acc)\n",
    "                    data[\"acc_stddev\"] = np.std(round_vals_acc)\n",
    "                    data[\"f1\"] = np.mean(round_vals_f1)\n",
    "                    data[\"f1_stddev\"] = np.std(round_vals_f1)\n",
    "                    data[\"eps\"] = np.mean(round_vals_eps)\n",
    "                    data[\"eps_stddev\"] = np.std(round_vals_eps)\n",
    "                    table_df4 = pd.concat([table_df4, pd.DataFrame(data, index=[0])])\n",
    "\n",
    "\n",
    "table_df4 = table_df4.round(decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (14, 4)})\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "# See results for non-iid training without client dropouts.\n",
    "add_metr = [\n",
    "    {\"dataset\": \"blond\", \"model\": \"cnn\", \"noise_multiplier\": 0.0, \"f1\": 0.77},\n",
    "    {\"dataset\": \"blond\", \"model\": \"lstm\", \"noise_multiplier\": 0.0, \"f1\": 0.77},\n",
    "    {\"dataset\": \"blond\", \"model\": \"resnet\", \"noise_multiplier\": 0.0, \"f1\": 0.74},\n",
    "    {\"dataset\": \"blond\", \"model\": \"densenet\", \"noise_multiplier\": 0.0, \"f1\": 0.74},\n",
    "    {\"dataset\": \"mnist\", \"model\": \"cnn\", \"noise_multiplier\": 0.0, \"f1\": 0.71},\n",
    "    {\"dataset\": \"shakespeare\", \"model\": \"lstm\", \"noise_multiplier\": 0.0, \"f1\": 0.53},\n",
    "]\n",
    "\n",
    "table_df4 = pd.concat([table_df4, pd.DataFrame(add_metr)])\n",
    "for strategy in [\"fedprox\", \"fedadam\", \"fedavg\", \"qfedavg\", \"fedyogi\", \"fedadagrad\"]:\n",
    "    tab4 = table_df4.loc[(table_df4[\"strategy\"] == strategy)]\n",
    "    pvt = tab4.pivot_table(index=[\"strategy\", \"dataset\", \"model\"], columns=\"noise_multiplier\", values=[\"f1\"], aggfunc=np.mean)\n",
    "\n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    pvt.plot(kind=\"bar\", ax=ax1, xlabel=\"\", ylabel=\"F1 Score\", width=0.8)\n",
    "    # ax1.set_xticklabels([\"CNN\", \"LSTM\", \"ResNet\", \"DenseNet\", \"CNN\", \"LSTM\"])\n",
    "    ax1.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    # Model axis\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.spines[\"bottom\"].set_position((\"axes\", -0.05))\n",
    "    ax2.tick_params('both', length=0, width=0, which='minor')\n",
    "    ax2.tick_params('both', direction='in', which='major')\n",
    "    ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "    ax2.xaxis.set_label_position(\"bottom\")\n",
    "\n",
    "    ax2.set_xticks([0.166, 0.333, 0.50, 0.666, 0.833])\n",
    "    ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax2.xaxis.set_minor_locator(ticker.FixedLocator([0.08, 0.246, 0.416, 0.586, 0.753, 0.913]))\n",
    "    ax2.xaxis.set_minor_formatter(ticker.FixedFormatter([\"CNN\", \"LSTM\", \"ResNet\", \"DenseNet\", \"CNN\", \"LSTM\"]))\n",
    "\n",
    "    # Dataset axis\n",
    "    ax3 = ax1.twiny()\n",
    "\n",
    "    ax3.spines[\"bottom\"].set_position((\"axes\", -0.13))\n",
    "    ax3.tick_params('both', length=0, width=0, which='minor')\n",
    "    ax3.tick_params('both', direction='in', which='major')\n",
    "    ax3.xaxis.set_ticks_position(\"bottom\")\n",
    "    ax3.xaxis.set_label_position(\"bottom\")\n",
    "\n",
    "    ax3.set_xticks([0.666, 0.833])\n",
    "    ax3.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax3.xaxis.set_minor_locator(ticker.FixedLocator([0.3333, 0.757, 0.913]))\n",
    "    ax3.xaxis.set_minor_formatter(ticker.FixedFormatter([\"BLOND\", \"FEMNIST\", \"Shakespeare\"]))\n",
    "\n",
    "    # Strategy axis\n",
    "    ax3 = ax1.twiny()\n",
    "\n",
    "    ax3.spines[\"bottom\"].set_position((\"axes\", -0.20))\n",
    "    ax3.tick_params('both', length=0, width=0, which='minor')\n",
    "    ax3.tick_params('both', direction='in', which='major')\n",
    "    ax3.xaxis.set_ticks_position(\"bottom\")\n",
    "    ax3.xaxis.set_label_position(\"bottom\")\n",
    "\n",
    "    ax3.set_xticks([])\n",
    "    ax3.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax3.xaxis.set_minor_locator(ticker.FixedLocator([0.5]))\n",
    "    ax3.xaxis.set_minor_formatter(ticker.FixedFormatter([f\"Strategy: {strategy.upper()}\"]))\n",
    "\n",
    "\n",
    "    round_10_eps = table_df4[[\"acc\", \"eps\"]][table_df4[\"round\"] == 10]\n",
    "    rects = ax1.patches\n",
    "\n",
    "\n",
    "    labels = [\"ε = ∞\", \"ε = ∞\", \"ε = ∞\", \"ε = ∞\", \"ε = ∞\", \"ε = ∞\", ]\n",
    "    labels += [\"ε = 8.0\", \"ε = 8.0\", \"ε = 8.0\", \"ε = 8.0\", \"ε = 6.1\", \"ε = 6.6\"]\n",
    "    labels += [\"ε = 2.3\", \"ε = 2.3\", \"ε = 2.3\", \"ε = 2.3\", \"ε = 2.1\", \"ε = 2.0\"]\n",
    "    labels += [\"ε = 0.4\", \"ε = 0.4\", \"ε = 0.4\", \"ε = 0.4\", \"ε = 0.4\", \"ε = 0.4\"]\n",
    "    labels += [\"ε = 0.2\", \"ε = 0.2\", \"ε = 0.2\", \"ε = 0.2\", \"ε = 0.3\", \"ε = 0.3\"]\n",
    "    labels += [\"ε = 0.2\", \"ε = 0.2\", \"ε = 0.2\", \"ε = 0.2\", \"ε = 0.3\", \"ε = 0.3\"]\n",
    "\n",
    "    label_pos_cor = 0\n",
    "    for idx, bar in enumerate(ax1.patches):\n",
    "        # format(bar.get_height(), '.2f')\n",
    "        ax1.annotate(labels[idx], (bar.get_x() + bar.get_width() / 2,bar.get_height() + 0.05), ha='center', va='center', size=12, xytext=(0, 8), textcoords='offset points', rotation=90)\n",
    "\n",
    "    ax1.legend([\"No DP\", \"z = 0.3\", \"z = 0.5\", \"z = 1.0\", \"z = 1.3\", \"z = 1.5\"], ncols=3, fontsize=10)\n",
    "    ax1.set_zorder(1)\n",
    "\n",
    "    plt.ylim(0, 1.15)\n",
    "    print(strategy)\n",
    "    utils.write_figure_to_disk(plt=plt, file_name=f\"dp_experiment_bar_chart_{strategy}\", chapter_name=\"evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

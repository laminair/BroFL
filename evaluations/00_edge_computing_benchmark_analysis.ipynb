{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analysis of Edge Computing Metrics\n",
    "Here, we analyze the first two of our four research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports\n",
    "import utils\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_path = os.path.dirname(os.path.realpath(\"00_edge_computing_benchmark_analysis.ipynb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn configuration\n",
    "# Alternative font: Linux Libertine\n",
    "sns.set_theme(context=\"paper\", style=\"whitegrid\", palette=\"colorblind\", font=\"Times New Roman\", font_scale=3)\n",
    "sns.color_palette(palette=\"colorblind\")\n",
    "sns.set(rc={\"figure.figsize\": (14, 3)})\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to expand the experiment name\n",
    "def expand_experiment_name(df: pd.DataFrame):\n",
    "    # 2023-05-31_17:38_flbench_experiment-plan-baseline_shakespeare_lstm_None_local_1_rounds_1_clients_0_dropout_nodp_0_prec_16_172.24.33.9_client_1\n",
    "    col_names = [\"date\", \"time\", \"experiment\", \"inventory\", \"dataset\", \"model\", \"strategy\", \"data_dist\",\n",
    "                 \"training_rounds\", \"pl1\", \"clients\", \"pl2\", \"dropout\", \"pl3\", \"dp\", \"noise_multiplier\", \"pl4\",\n",
    "                 \"precision\", \"ip_addr\", \"pl5\", \"client_id\"]\n",
    "    df[col_names] = df[\"name\"].str.split(\"_\", expand=True)\n",
    "    df.drop([\"pl1\", \"pl2\", \"pl3\", \"pl4\"], inplace=True, axis=1)\n",
    "    df[\"timestamp\"] = df[[\"date\", \"time\"]].apply(\" \".join, axis=1)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M\")\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download / load from disk\n",
    "wandb_entity = \"...\"                                                                                                        # <-- Add you credentials for W&B here.\n",
    "wandb_project = \"...\"                                                                                                       # <-- Add you credentials for W&B here.\n",
    "wandb_run_filter_keywords = [\"...\"]                                                                                         # <-- Filter for whatever keyword you are looking for.\n",
    "log_file_name = \"wandb_baseline_logs.csv\"\n",
    "\n",
    "if not Path(f\"{notebook_path}/data/{log_file_name}\").exists():\n",
    "\t# If logs have been downloaded already, they will be fetched from disk.\n",
    "\tdf = utils.download_data_from_wandb(entity=wandb_entity, project=wandb_project, keywords=wandb_run_filter_keywords)\n",
    "\tutils.write_df_to_disk(df, filename=log_file_name)\n",
    "\tdf = expand_experiment_name(df)\n",
    "\tutils.write_df_to_disk(df, filename=log_file_name)\n",
    "else:\n",
    "\tdf = pd.read_csv(f\"{notebook_path}/data/{log_file_name}\", index_col=0)\n",
    "\tdf = expand_experiment_name(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace IP addresses with device type names\n",
    "df[\"ip_addr2\"] = df[\"ip_addr\"]\n",
    "print(df[\"ip_addr\"].unique())\n",
    "df[\"ip_addr2\"].replace([\"172.24.32.1\", \"172.24.32.2\", \"172.24.32.3\", \"172.24.32.52\", \"172.24.32.53\", \"172.24.32.54\", \"172.24.33.72\", \"172.24.33.74\", \"172.24.33.82\", \"172.24.33.9\"], [\"3raspi\", \"3raspi\", \"3raspi\", \"2jnano\", \"2jnano\", \"2jnano\", \"1vm\", \"1vm\", \"1vm\", \"0gpu\"], inplace=True)\n",
    "df.rename({\"ip_addr2\": \"device\"}, inplace=True, axis=1)\n",
    "\n",
    "# For VMs we use SelfWatts estimate of a 4 CPU (x86) VM in the same system as ours.\n",
    "# Source (Fig .4): https://inria.hal.science/hal-03173410/document\n",
    "df.loc[df[\"device\"] == \"1vm\", \"power/wattage\"] = 50_000 # mW\n",
    "print(df[\"device\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RQ 1: Microbenchmark for embedded devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df[[\"timing/train/batch_load_time_s\", \"timing/train/forward_time\", \"timing/train/loss_calc_time_s\", \"timing/train/backward_s\", \"timing/train/optimizer_s\", \"device\", \"dataset\", \"model\"]].copy(deep=True)\n",
    "subset.rename({\"timing/train/batch_load_time_s\": \"0batch_load\", \"timing/train/forward_time\": \"1forward\", \"timing/train/loss_calc_time_s\": \"2loss\", \"timing/train/backward_s\": \"3back\", \"timing/train/optimizer_s\": \"4optim\"}, inplace=True, axis=1)\n",
    "# We need this cleaning as on the Jnano's the first batch takes 170x longer than all other batches to load, which is an issue with the way how pytorch interacts with the custom CUDA on the Nanos.\n",
    "subset = subset.loc[subset[\"0batch_load\"] < subset[\"0batch_load\"].quantile(.997)]\n",
    "subset[\"total_step_time\"] = subset[\"0batch_load\"] + subset[\"1forward\"] + subset[\"2loss\"] + subset[\"3back\"] + subset[\"4optim\"]\n",
    "\n",
    "subset[\"model\"] = subset[\"model\"].replace({\"cnn\": \"0cnn\", \"lstm\": \"1lstm\", \"densenet\": \"3densenet\", \"resnet\": \"2resnet\"})\n",
    "pvt = subset.pivot_table(index=[\"dataset\", \"model\", \"device\"], values=[\"0batch_load\", \"1forward\", \"2loss\", \"3back\", \"4optim\", \"total_step_time\"], aggfunc=np.mean)\n",
    "pvt = pvt.round(2)\n",
    "\n",
    "fig, ax1 = plt.subplots(1)\n",
    "pvt.plot(kind=\"bar\", stacked=True, xlabel=\"\", ylabel=\"Time (in s)\", ax=ax1, y=[\"0batch_load\", \"1forward\", \"2loss\", \"3back\", \"4optim\"])\n",
    "ax1.legend([\"Batch Loading\", \"Forward Step\", \"Loss Calculation\", \"Backward Step\", \"Optimizer Step\"])\n",
    "utils.format_xaxis(ax1=ax1, ymax=8)\n",
    "ax1.bar_label(ax1.containers[-1], size=12)\n",
    "\n",
    "# Legend format\n",
    "plt.ylim(0, 8.5)\n",
    "\n",
    "utils.write_figure_to_disk(plt=plt, file_name=\"microbenchmark\", chapter_name=\"evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Speedup table\n",
    "# We use the Jetson Nanos as baseline and provide a speed up comparison for all other devices\n",
    "# pvt.reset_index(inplace=True)\n",
    "speed_pvt = subset.pivot_table(index=[\"dataset\", \"model\", \"device\"], values=[\"0batch_load\", \"1forward\", \"2loss\", \"3back\", \"4optim\", \"total_step_time\"], aggfunc=[np.mean, np.std])\n",
    "speed_pvt.reset_index(inplace=True)\n",
    "speed_data_raw = []\n",
    "for dataset in [\"blond\", \"mnist\", \"shakespeare\"]:\n",
    "\tfor model in [\"0cnn\", \"1lstm\", \"2resnet\", \"3densenet\"]:\n",
    "\t\tfor basis in [\"0gpu\", \"1vm\", \"2jnano\", \"3raspi\"]:\n",
    "\t\t\tbasis_set = speed_pvt.loc[(speed_pvt[\"device\"] == basis) & (speed_pvt[\"dataset\"] == dataset) & (speed_pvt[\"model\"] == model)].copy()\n",
    "\n",
    "\t\t\tif len(basis_set) == 0:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tfor target in [\"0gpu\", \"1vm\", \"2jnano\", \"3raspi\"]:\n",
    "\t\t\t\ttarget_set = speed_pvt.loc[(speed_pvt[\"device\"] == target) & (speed_pvt[\"dataset\"] == dataset) & (speed_pvt[\"model\"] == model)].copy()\n",
    "\t\t\t\tfor step in [\"0batch_load\", \"1forward\", \"2loss\", \"3back\", \"4optim\", \"total_step_time\"]:\n",
    "\t\t\t\t\tdata = {\n",
    "\t\t\t\t\t\t\"Dataset\": dataset,\n",
    "\t\t\t\t\t\t\"Model\": model,\n",
    "\t\t\t\t\t\t\"basis\": basis,\n",
    "\t\t\t\t\t\t\"target\": target,\n",
    "\t\t\t\t\t\t\"Step\": step,\n",
    "\t\t\t\t\t\t\"mean\": target_set[(\"mean\", step)].tolist()[0] / basis_set[(\"mean\", step)].tolist()[0],\n",
    "\t\t\t\t\t\t\"std\": target_set[(\"std\", step)].tolist()[0] / basis_set[(\"std\", step)].tolist()[0],\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\tspeed_data_raw.append(data)\n",
    "\n",
    "speed_info = pd.DataFrame(speed_data_raw)\n",
    "pvt_speed = speed_info.pivot_table(index=[\"Dataset\", \"Model\", \"basis\"], columns=[\"Step\", \"target\"], values=[\"mean\", \"std\"], aggfunc=np.mean)\n",
    "pvt_speed.fillna(1, inplace=True)\n",
    "# pvt_speed = pvt_speed.round(2).astype(str)\n",
    "\n",
    "for val_type, step, device in [i for i in pvt_speed.columns]:\n",
    "\tif val_type != \"mean\":\n",
    "\t\tcontinue\n",
    "\n",
    "\tpvt_speed[(val_type, step, device)] = pvt_speed[(val_type, step, device)].round(decimals=2).astype(str)+ \"±\" + pvt_speed[(\"std\", step, device)].round(decimals=1).astype(str)\n",
    "    # if \"_stddev\" not in acc:\n",
    "    #     piv3[(acc, dataset, model)] = piv3[(acc, dataset, model)].round(decimals=4).astype(str)+ \"±\" + piv3[(f\"{acc}_stddev\", dataset, model)].round(decimals=2).astype(str)\n",
    "    # else:\n",
    "    #     piv3.drop((acc, dataset, model), inplace=True, axis=1)\n",
    "\n",
    "\n",
    "s = pvt_speed[\"mean\"].style.highlight_max(props='cellcolor:[HTML]{FFFF00}; color:{red}; itshape:; bfseries:;')\n",
    "s.clear()\n",
    "s.table_styles = []\n",
    "s.format({\n",
    "\t(\"Numeric\", \"Integers\"): '\\${}',\n",
    "\t(\"Numeric\", \"Floats\"): '{:.2f}',\n",
    "    (\"Non-Numeric\", \"Strings\"): str.upper\n",
    "})\n",
    "print(s.to_latex(column_format=\"lll|rrrr|rrrr|rrrr|rrrr|rrrr|rrrr\", position=\"\", position_float=\"centering\", hrules=True, label=\"tab:speedup-comparison\", caption=\"Speedup comparison across device types, datasets, and ML models.\", multirow_align=\"t\", multicol_align=\"r\"))\n",
    "# column_format=\"rrllllllllllllllllllllllll\", position=\"h\", position_float=\"centering\", hrules=True, label=\"table:5\", caption=\"Speedup comparison across device types, datasets, and ML models.\", multirow_align=\"t\", multicol_align=\"r\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RQ 2: Energy & Cost Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download system metrics for GPU power consumption\n",
    "sys_file_name = \"wandb_system_logs_gpu_v2.csv\"\n",
    "sys_ids = df.loc[df[\"device\"] == \"0gpu\", \"id\"].unique().tolist()\n",
    "\n",
    "if not Path(f\"{notebook_path}/data/{sys_file_name}\").exists():\n",
    "\t# If logs have been downloaded already, they will be fetched from disk.\n",
    "\tsys_metrics = utils.download_system_metrics(run_ids=sys_ids, entity=wandb_entity, project=wandb_project)\n",
    "\tdf = expand_experiment_name(sys_metrics)\n",
    "\tutils.write_df_to_disk(sys_metrics, filename=sys_file_name)\n",
    "else:\n",
    "\tsys_metrics = pd.read_csv(f\"{notebook_path}/data/{sys_file_name}\", index_col=0)\n",
    "\n",
    "sys_metrics[\"ip_addr2\"] = sys_metrics[\"ip_addr\"]\n",
    "sys_metrics[\"ip_addr2\"].replace([\"172.24.32.1\", \"172.24.32.2\", \"172.24.32.3\", \"172.24.32.52\", \"172.24.32.53\", \"172.24.32.54\", \"172.24.33.72\", \"172.24.33.74\", \"172.24.33.82\", \"172.24.33.9\"], [\"3raspi\", \"3raspi\", \"3raspi\", \"2jnano\", \"2jnano\", \"2jnano\", \"1vm\", \"1vm\", \"1vm\", \"0gpu\"], inplace=True)\n",
    "sys_metrics[\"model\"] = sys_metrics[\"model\"].replace({\"cnn\": \"0cnn\", \"lstm\": \"1lstm\", \"densenet\": \"2densenet\", \"resnet\": \"3resnet\"})\n",
    "sys_metrics.rename({\"ip_addr2\": \"device\"}, inplace=True, axis=1)\n",
    "sys_metrics.set_index([\"dataset\", \"model\", \"device\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we consider the training samples only.\n",
    "summary_metrics_file_name = \"wandb_summary_metrics.csv\"\n",
    "run_ids = df[\"id\"].unique().tolist()\n",
    "sample_sizes = {\n",
    "\t\"blond\": {\"batch_size\": 128, \"total_samples\": 13164},\n",
    "\t\"mnist\": {\"batch_size\": 32, \"total_samples\": 270000},\n",
    "\t# We cut the shakespeare experiment short for runtime reasons. Results are scaled to full trainset size of 0.8 * 3,380,926\n",
    "\t\"shakespeare\": {\"batch_size\": 32, \"total_samples\": 8000} # Only the GPU trained on the full dataset.\n",
    "}\n",
    "\n",
    "e_subset = df[[\"id\", \"dataset\", \"model\", \"device\", \"timing/train/batch_load_time_s\", \"timing/train/forward_time\", \"timing/train/loss_calc_time_s\", \"timing/train/backward_s\", \"timing/train/optimizer_s\", \"power/wattage\", \"id\"]].copy(deep=True)\n",
    "e_subset[\"model\"] = e_subset[\"model\"].replace({\"cnn\": \"0cnn\", \"lstm\": \"1lstm\", \"densenet\": \"2densenet\", \"resnet\": \"3resnet\"})\n",
    "e_subset.set_index([\"dataset\", \"model\", \"device\"], inplace=True)\n",
    "\n",
    "# For VMs we use SelfWatts estimate of a 4 CPU (x86) VM in the same system as ours.\n",
    "# Source (Fig .4): https://inria.hal.science/hal-03173410/document\n",
    "vm_power = 50\n",
    "gpu_power = sys_metrics.groupby(sys_metrics.index)[\"system.gpu.0.powerWatts\"].mean() * 1000\n",
    "wattage_df = e_subset.groupby(e_subset.index)[\"power/wattage\"].mean()\n",
    "idx_values = e_subset.index.tolist()\n",
    "\n",
    "wattage_df = wattage_df.combine(gpu_power, func=max)\n",
    "e_subset = e_subset.loc[e_subset[\"timing/train/batch_load_time_s\"] < e_subset[\"timing/train/batch_load_time_s\"].quantile(.997)]\n",
    "pvt2 = e_subset.pivot_table(index=e_subset.index, values=[\"power/wattage\", \"timing/train/batch_load_time_s\", \"timing/train/forward_time\", \"timing/train/loss_calc_time_s\", \"timing/train/backward_s\", \"timing/train/optimizer_s\"], aggfunc=[np.mean, np.std])\n",
    "idx_list = pvt2.index.tolist()\n",
    "pvt2.index = pd.MultiIndex.from_tuples(idx_list)\n",
    "\n",
    "pvt2[(\"mean\", \"power/wattage\")] = wattage_df\n",
    "\n",
    "idx_list = pvt2.index.tolist()\n",
    "\n",
    "for dataset, model, device in idx_list:\n",
    "\tpvt2.loc[(dataset, model, device), (\"mean\", \"timing/training_time\")] = (pvt2.loc[(dataset, model, device), (\"mean\", \"timing/train/batch_load_time_s\")] + pvt2.loc[(dataset, model, device), (\"mean\", \"timing/train/forward_time\")] + pvt2.loc[(dataset, model, device), (\"mean\", \"timing/train/loss_calc_time_s\")] + pvt2.loc[(dataset, model, device), (\"mean\", \"timing/train/backward_s\")] + pvt2.loc[(dataset, model, device), (\"mean\", \"timing/train/optimizer_s\")]) * (sample_sizes[dataset][\"total_samples\"] / sample_sizes[dataset][\"batch_size\"])\n",
    "\tpvt2.loc[(dataset, model, device), (\"std\", \"timing/training_time\")] = (pvt2.loc[(dataset, model, device), (\"std\", \"timing/train/batch_load_time_s\")] + pvt2.loc[(dataset, model, device), (\"std\", \"timing/train/forward_time\")] + pvt2.loc[(dataset, model, device), (\"std\", \"timing/train/loss_calc_time_s\")] + pvt2.loc[(dataset, model, device), (\"std\", \"timing/train/backward_s\")] + pvt2.loc[(dataset, model, device), (\"std\", \"timing/train/optimizer_s\")]) * (sample_sizes[dataset][\"total_samples\"] / sample_sizes[dataset][\"batch_size\"])\n",
    "\n",
    "\tpvt2.loc[(dataset, model, device), (\"mean\", \"throughput_sps\")] = sample_sizes[dataset][\"total_samples\"] / pvt2.loc[(dataset, model, device), (\"mean\", \"timing/training_time\")]\n",
    "\tpvt2.loc[(dataset, model, device), (\"std\", \"throughput_sps\")] = sample_sizes[dataset][\"total_samples\"] / pvt2.loc[(dataset, model, device), (\"std\", \"timing/training_time\")]\n",
    "\n",
    "pvt2.drop([(\"mean\", \"timing/train/batch_load_time_s\"), (\"mean\", \"timing/train/forward_time\"), (\"mean\", \"timing/train/loss_calc_time_s\"), (\"mean\", \"timing/train/backward_s\"), (\"mean\", \"timing/train/optimizer_s\"), (\"std\", \"timing/train/batch_load_time_s\"), (\"std\", \"timing/train/forward_time\"), (\"std\", \"timing/train/loss_calc_time_s\"), (\"std\", \"timing/train/backward_s\"), (\"std\", \"timing/train/optimizer_s\")], axis=1)\n",
    "# Convert milliwatt to watt\n",
    "pvt2[(\"mean\", \"power/wattage\")] = pvt2[(\"mean\", \"power/wattage\")] / 1000\n",
    "pvt2[(\"std\", \"power/wattage\")] = pvt2[(\"std\", \"power/wattage\")] / 1000\n",
    "# Get total energy consumption for experiment\n",
    "pvt2[(\"mean\", \"power/total_energy_wh\")] = pvt2[(\"mean\", \"power/wattage\")] * (pvt2[(\"mean\", \"timing/training_time\")] / (60 * 60))\n",
    "pvt2[(\"std\", \"power/total_energy_wh\")] = pvt2[(\"std\", \"power/wattage\")] * (pvt2[(\"std\", \"timing/training_time\")] / (60 * 60))\n",
    "for device in [\"1vm\", \"2jnano\", \"3raspi\"]:\n",
    "\tpvt2.loc[(\"shakespeare\", \"1lstm\", device), (\"mean\", \"power/total_energy_wh\")] = pvt2.loc[(\"shakespeare\", \"1lstm\", device), (\"mean\", \"power/total_energy_wh\")] * ((3_380_926*0.8) / 10000)  # We interpolate the training performance based on 10k samples from the logs.\n",
    "\tpvt2.loc[(\"shakespeare\", \"1lstm\", device), (\"std\", \"power/total_energy_wh\")] = pvt2.loc[(\"shakespeare\", \"1lstm\", device), (\"std\", \"power/total_energy_wh\")] * ((3_380_926*0.8) / 10000)  # We interpolate the training performance based on 10k samples from the logs.\n",
    "\n",
    "# Create sample efficiency metric\n",
    "pvt2[(\"mean\", \"sample_efficiency\")] = pvt2[(\"mean\", \"throughput_sps\")] / pvt2[(\"mean\", \"power/wattage\")]\n",
    "pvt2[(\"std\", \"sample_efficiency\")] = pvt2[(\"std\", \"throughput_sps\")] / pvt2[(\"std\", \"power/wattage\")]\n",
    "pvt2 = pvt2.round(0)\n",
    "print(pvt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample efficiency chart\n",
    "fig, ax1 = plt.subplots(1)\n",
    "plt.rcParams['text.usetex'] = True\n",
    "pvt2[(\"mean\", \"sample_efficiency\")].plot(kind=\"bar\", stacked=False, xlabel=\"\", ylabel=\"$\\\\eta_e = \\\\frac{SPS}{W}$\", ax=ax1, yerr=pvt2[\"std\"])\n",
    "utils.format_xaxis(ax1=ax1, ymax=112)\n",
    "ax1.bar_label(ax1.containers[-1], size=14)\n",
    "utils.write_figure_to_disk(plt=plt, file_name=\"sample_efficiency\", chapter_name=\"evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done with Edge Evaluations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
